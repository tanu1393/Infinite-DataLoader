{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8ars855prMbk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "#!unzip hymenoptera_data.zip\n"
      ],
      "metadata": {
        "id": "xO4E-MWs2EF-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/train_inf.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wJfAeUyJq5K",
        "outputId": "d85fc15d-f6a6-45cb-dfbf-b8aaf612eb35"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train_inf.zip\n",
            "   creating: train_inf/train/\n",
            "   creating: train_inf/train/ants_5/\n",
            "  inflating: train_inf/train/ants_5/0013035.jpg  \n",
            "  inflating: train_inf/train/ants_5/5650366_e22b7e1065.jpg  \n",
            "  inflating: train_inf/train/ants_5/6240329_72c01e663e.jpg  \n",
            "  inflating: train_inf/train/ants_5/6240338_93729615ec.jpg  \n",
            "  inflating: train_inf/train/ants_5/6743948_2b8c096dda.jpg  \n",
            "   creating: train_inf/train/bees_5/\n",
            "  inflating: train_inf/train/bees_5/16838648_415acd9e3f.jpg  \n",
            "  inflating: train_inf/train/bees_5/17209602_fe5a5a746f.jpg  \n",
            "  inflating: train_inf/train/bees_5/21399619_3e61e5bb6f.jpg  \n",
            "  inflating: train_inf/train/bees_5/29494643_e3410f0d37.jpg  \n",
            "  inflating: train_inf/train/bees_5/36900412_92b81831ad.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "class InfiniteDataLoader(DataLoader):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # Initialize an iterator over the dataset.\n",
        "        self.dataset_iterator = super().__iter__()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            batch = next(self.dataset_iterator)\n",
        "        except StopIteration:\n",
        "            # Dataset exhausted, use a new fresh iterator.\n",
        "            self.dataset_iterator = super().__iter__()\n",
        "            batch = next(self.dataset_iterator)\n",
        "        return batch"
      ],
      "metadata": {
        "id": "2dKt3wBN6ofu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "RgBzMWDYrr3F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/train_inf'"
      ],
      "metadata": {
        "id": "g3g5-ZmMr8Cr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train']}"
      ],
      "metadata": {
        "id": "bJxLt6hgsDP5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {x: InfiniteDataLoader(image_datasets[x], batch_size=2,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train']}"
      ],
      "metadata": {
        "id": "RbDFMX5SsIHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f8e4c8-e3c6-4eaa-ded1-856cddd61ebf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train']}"
      ],
      "metadata": {
        "id": "b5fUzR0osMo7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaXmd8Ss5UzP",
        "outputId": "26033423-58b9-4e93-a847-21b34c7fdf73"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = image_datasets['train'].classes\n"
      ],
      "metadata": {
        "id": "VNscZ3cw5Wpb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYFf_NWe5aq1",
        "outputId": "d966c2c8-a627-48e6-dcc6-c7a4268d083e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ants_5', 'bees_5']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  batch_images, batch_labels = next(iter(dataloaders['train']))\n",
        "  print(f'Batch {i+1}: {batch_images.shape}, {batch_labels.shape}')  "
      ],
      "metadata": {
        "id": "bubIqaZw5nXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09dbf29-fd96-4d1d-94cf-5359702f7ecf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 2: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 3: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 4: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 5: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 6: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 7: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 8: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 9: torch.Size([2, 3, 224, 224]), torch.Size([2])\n",
            "Batch 10: torch.Size([2, 3, 224, 224]), torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DlXKYQxB6b0o"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}